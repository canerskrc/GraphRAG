{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk+hfmkT48mENqe36crOkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canerskrc/GraphRAG/blob/main/GraphRAG_Dependency_Management.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFFBz7s4wwOe"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Step 1: Create a graph to model software dependencies\n",
        "dependency_graph = nx.DiGraph()\n",
        "\n",
        "# Add nodes (libraries, versions, features)\n",
        "dependency_graph.add_node(\"Django\", version=\"4.0\", description=\"A Python web framework for rapid development.\")\n",
        "dependency_graph.add_node(\"Django\", version=\"3.2\", description=\"An older version of Django with long-term support (LTS).\")\n",
        "dependency_graph.add_node(\"DRF\", version=\"3.12\", description=\"Django REST Framework for building REST APIs.\")\n",
        "dependency_graph.add_node(\"DRF\", version=\"3.14\", description=\"Latest DRF version with advanced features.\")\n",
        "dependency_graph.add_node(\"Python\", version=\"3.8\", description=\"Python programming language version 3.8.\")\n",
        "dependency_graph.add_node(\"Python\", version=\"3.10\", description=\"Python programming language version 3.10.\")\n",
        "\n",
        "# Add edges to represent compatibility and dependencies\n",
        "dependency_graph.add_edges_from([\n",
        "    (\"Django 4.0\", \"Python 3.10\", {\"type\": \"requires\"}),\n",
        "    (\"Django 3.2\", \"Python 3.8\", {\"type\": \"requires\"}),\n",
        "    (\"DRF 3.14\", \"Django 4.0\", {\"type\": \"requires\"}),\n",
        "    (\"DRF 3.12\", \"Django 3.2\", {\"type\": \"requires\"})\n",
        "])\n",
        "\n",
        "# Step 2: Retrieve relevant nodes based on query\n",
        "def retrieve_relevant_nodes(query, graph):\n",
        "    relevant_nodes = []\n",
        "    for node, data in graph.nodes(data=True):\n",
        "        if query.lower() in str(node).lower() or query.lower() in str(data.get('description', '')).lower():\n",
        "            relevant_nodes.append((node, data))\n",
        "    return relevant_nodes\n",
        "\n",
        "# Step 3: Generate chatbot response using relevant nodes\n",
        "def generate_response(query, retrieved_nodes):\n",
        "    context = f\"Query: {query}\\nRelevant Information:\\n\"\n",
        "    for node, data in retrieved_nodes:\n",
        "        description = data.get(\"description\", \"No description available.\")\n",
        "        context += f\"{node}: {description}\\n\"\n",
        "\n",
        "    # Load pre-trained language model\n",
        "    model_name = \"gpt2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    # Generate response\n",
        "    input_ids = tokenizer.encode(context, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(input_ids, max_length=200, num_return_sequences=1)\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Step 4: Chatbot function to integrate retrieval and generation\n",
        "def chatbot(query):\n",
        "    retrieved_nodes = retrieve_relevant_nodes(query, dependency_graph)\n",
        "    if retrieved_nodes:\n",
        "        response = generate_response(query, retrieved_nodes)\n",
        "        return response\n",
        "    else:\n",
        "        return \"I couldn't find any relevant information for your query. Please refine your question.\"\n",
        "\n",
        "# Example interaction\n",
        "user_query = \"How can I resolve a conflict between Django 4.0 and DRF 3.12?\"\n",
        "response = chatbot(user_query)\n",
        "\n",
        "# Display chatbot's response\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"Chatbot Response:\", response)\n"
      ]
    }
  ]
}